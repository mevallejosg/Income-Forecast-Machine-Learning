# -*- coding: utf-8 -*-
"""20172932_EF.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mLlSZDJYD8P8jR0QLWkqSsrgrlAzpmUE

# **PREDICCIÓN DE INGRESOS USANDO ENAHO**

Autor: Mauricio Elias Vallejos Garcia

Correo: mauricio.vallejos@pucp.edu.pe

### PARTE I: Trabajo preliminar
"""

### Librerias con las que vamos a trabajar

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

from xgboost import XGBClassifier
from xgboost import XGBRegressor

from numpy import absolute
from pandas import read_csv

from sklearn import metrics
from sklearn import linear_model

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedKFold
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score

from sklearn.metrics import f1_score, roc_auc_score,accuracy_score, precision_score, recall_score
from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error 

from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LassoCV

from sklearn.feature_selection import RFE
from sklearn.feature_selection import SelectKBest

from sklearn.preprocessing import MaxAbsScaler
from sklearn.preprocessing import PolynomialFeatures

from scipy.stats import pointbiserialr, spearmanr
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier

from google.colab import drive

import warnings 
warnings.filterwarnings("ignore")

# Definimos el directorio para trabajar
drive.mount('/content/drive')

cd '/content/drive/MyDrive/PUCP - ECONOMÍA/CICLO 2022-1/PROGRAMACIÓN EN FINANZAS/final'

df = pd.read_csv("base_exfinal.csv")

# Creamos una función para realizar la distribución de nuestros gráficos
def dis_data(Rfunction, Bfunction, Rname, Bname, title):
    plt.figure(figsize=(10,6))
    ax1 = sns.distplot(Rfunction, hist = False, color = 'r', label = Rname)
    ax1 = sns.distplot(Bfunction, hist = False, color = 'b', label = Bname)
    plt.title(title)
    plt.show()
    plt.close()

df.head()

"""### PARTE II: A continuación, crearemos un código para identificar todas las posibles variables candidatas de la base para ser predictoras del ingreso. Para ello calculamos la correlación (o el estadístico correspondinete) entre la variable y el logaritmo del ingreso. Además, presentaremos en una tabla las 10 variables con mayor correlación así como los gráficos que muestren el sentido que económico de las variables.


"""

df['ln_ingreso'] = np.log(df['ingreso_mensualizado'])

df['ln_ingreso'].describe()

# Reemplazamos los missings
df=df.replace(r'^\s*$', np.nan, regex=True)
df

# Corregimos los outliers
def CORREGIR_OUTLIER(x, p_lower,p_upper):
    if (x<p_lower):
        return p_lower
    elif (x>p_upper):
        return p_upper
    else:
        return x

p_1 = np.percentile(df["P301A"], 0.5)
p_99 = np.percentile(df["P301A"],99)
print("el percentile p1 es {0} y el p99 es {1}".format(p_1,p_99))
df["P301A"] = df["P301A"].apply(lambda x: CORREGIR_OUTLIER(x,p_1,p_99))

# Observamos la correlación
df.corr('pearson')['ln_ingreso']

# Creamos un código para ordenar la correlación
df_corr=pd.DataFrame(df.corr('pearson')['ln_ingreso'])
df_corr['ln_ingreso'] = np.abs(df_corr['ln_ingreso'])
df_corr=df_corr.sort_values('ln_ingreso', ascending=False)
df_corr=df_corr.dropna()

df_corr

""" Por lo tanto nos quedamos con las 10 primeras variables:

 - OCUPINF (Situación de informalidad (ocup.principal)), 
 - P558A5 (¿El Sistema de pensiones al cual Ud. está afiliado es:),
 - P5441A (En los últimos 12 meses, de ... a ... ¿Recibió algún dinero por: Gratificación de navidad?), 
 - P5442A (En los últimos 12 meses, de ... a ... ¿Recibió algún dinero por: Gratificación de fiestas patrias?)), 
 - P505 (¿Cuál es la ocupación principal que desempeño? (revisión CNO-2015)), 
 - P4191 (El sistema de prestación de seguro de salud al cual Ud. está afiliado actualmente es: ¿EsSalud?)), 
 - P505R4 (¿Cuál es la ocupación principal que desempeño? (revisión CNO-2015)), 
 - P4195 (El sistema de prestación de seguro de salud al cual Ud. está afiliado actualmente es: ¿Seguro integral de salud (SIS)?) , 
 - P558A1 (¿El Sistema de pensiones al cual Ud. está afiliado es: Sistema privado de pensiones ( AFP)?)), 
 - P301A (¿Cuál es el último año o grado de estudios y nivel que aprobó? - Nivel 1).


** Sin embargo, algunas variables pueden llegar a ser redundantes entre sí, por lo que se seleccionaran solo las 10 primeras que no incurran en este problema. Tampoco consideramos transferencias de dinero como bonos.**

 - OCUPINF (Situación de informalidad (ocup.principal)), 
 - P4195 (El sistema de prestación de seguro de salud al cual Ud. está afiliado actualmente es: ¿Seguro integral de salud (SIS)?) , 
 - P558A1 (¿El Sistema de pensiones al cual Ud. está afiliado es: Sistema privado de pensiones ( AFP)?)), 
 - P301A (¿Cuál es el último año o grado de estudios y nivel que aprobó? - Nivel 1).
 - P507 (Ud. se desempeño en su ocupación principal o negocio como:)
 - ESTRATO_x.1 (ESTRATO_x.1)
 - P513A1 ¿Cuánto tiempo trabaja Ud., en esta Ocupación Principal? - Años)
 - P208A (¿Qúe edad tiene en años cumplidos? (En años) )
 - P558D2_1 (El lugar donde desempeña su ocupación principal (trabajo), ¿Está ubicado:)
 - P513T (¿Cuántas horas trabajó la semana pasada, en su ocupación principal, el día: Total )


** Además tenemos algunas variables extras seleccionadas en caso de tener alta correlación entre las seleccionadas y considerar el posible problema de multicolinealidad**

 - P522A (La semana pasada ¿Ha realizado su trabajo?  Presencial Virtual)
 - P407I (¿Le realizaron alguna prueba para descartar el COVID-19? )
 - P514 (¿Además de su ocupación principal la semana pasada, ¿Tuvo Ud. otro trabajo para obtener ingresos?)
 - P209_y (¿Cuál es su estado civil o conyugal?)
 - P558C (Por sus antepasados y de acuerdo a sus costumbres, ¿ud. se considera:)
 - P207 (Sexo)


"""

variables=df[["ln_ingreso", "OCUPINF", "P558A5", "P5441A", "P5442A", "P505", "P4191", "P505R4", "P4195","P558A1", "P301A", "P507", "ESTRATO_x.1", "P513A1", "P208A_y", "P558D2_1", "P513T", "P522A", "P407I", "P514", "P209_y", "P558C", "P207_y"]]

plt.figure(figsize=(16, 6))

heatmap = sns.heatmap(variables.corr(), vmin=-1, vmax=1, annot=True)
heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12)

"""De dicha observación seleccionamos variables que tengan sentido económico y además sean relevantes una a una"""

variables_finales = df[["ln_ingreso", "OCUPINF", "P522A", "P558A1","P301A", "P513T", "P507", "ESTRATO_x","P513A1", "P208A_y.1","P558D2_1"]]

plt.figure(figsize=(20, 10))

 heatmap = sns.heatmap(variables_finales.corr(), vmin=-1, vmax=1, annot=True) 
 heatmap.set_title('Mapa de calor de correlación', fontdict={'fontsize':12}, pad=12)

#Gráficas de Correlación 
variables['OCUPINF'].replace([1,2],['Informal','Formal'],inplace=True)
variables.plot.scatter('OCUPINF','ln_ingreso', marker ="+", s = 100, title="Situación de informalidad", color="purple") 

plt.show()

"""En este se aprecia que los trabajadores formales son los que reciben una mayor remuneración en comparación con los trabajadores del sector informal."""

variables['P522A'].replace([1,2,3,4,5,6,7],['Presencial 24/7','Presencial','Remoto','Teletrabajo','Vacaciones','Otra','Sin labores'],inplace=True)
variables.plot.scatter('P522A','ln_ingreso', marker ="+", s = 30, title="Trabajo remoto", color="red", figsize=(16, 5)) # En

"""Para el caso de esta variable, se aprecia que existe una mayor proporción por aquellos que hacen trabajo presencial total. En el caso de ellos, la distribución de los salarios se muestra pareja a lo largo de los valores de la variable. Sin embargo, es rescatable apreciar que solo hacen trabajo remoto aquellos que se encuentran por encima del valor 5 en la escala del 2 al 10. De esta manera, podríamos inferior que solo hacen trabajo remoto aquellos que que se encuentran sobre un umbral de ingresos."""

variables['P558A1'].replace([0,1],['Otro','AFP'],inplace=True)
variables.plot.scatter('P558A1','ln_ingreso', marker ="+", s = 30, title="¿Sistema privado de pensiones?", color="blue") #

plt.show()

"""Los que se encuentran en el sistema de pensiones privado tienen mayores ingresos que aquellos que ocupan otro sistema de pensiones."""

variables.plot.scatter('P301A','ln_ingreso', marker ="+", s = 30, title="Último año o grado de estudios", color="green") #

plt.show()

"""En este caso, se observa que progresivamente aumentan los salarios conforme aumentan los años de educación."""

variables_finales.plot.scatter('P513T','ln_ingreso', marker ="+", s = 30, title="Horas de trabajo", color="purple") #

plt.show()

"""Aquellos que realizán mayor cantidad d ehoras de trabajo reciben un mayor ingreso. Tiene sentido económico esta interpretación. Luego están aquellos que no realizan horas de trabajo, pero aun así reciben ingreso. Esto se podría explicar porque reciben algún tipo de pensión."""

variables['P507'].replace([1,2,3,4,5,6,7],['Empleador','Independiente','Empleado','Obrero','Familiar no remunerado','Trabajador del hogar','Otro'],inplace=True)

variables.plot.scatter('P507','ln_ingreso', marker ="+", s = 30, title="Posición en ocupación principal", color="red") #

plt.show()

"""Los empleados y obreros se distribuyen a lo largo de los diferentes posibles valores par alos ingresos. Sin embargo, los trabajadores dle hogar solo se encuentra por debajo de cierto umbral."""

variables['ESTRATO_x.1'].replace([1,2,3,4,5,6,7,8],['De 500 000 a más habitantes','De 100 000 a 499 999 habitantes','De 50 000 a 99 999 habitantes','De 20 000 a 49 999 habitantes','De 2 000 a 19 999 habitantes','De 500 a 1 999 habitantes','(AER) Compuesto','(AER) Simple'],inplace=True)

variables.plot.scatter('ESTRATO_x.1','ln_ingreso', marker ="+", s = 30, title="Estrato", color="red", figsize=(25, 5))
plt.show()

variables_finales.plot.scatter('P513A1','ln_ingreso', marker ="+", s = 30, title="Experiencia en esta ocupación", color="green") #

plt.show()

"""A mayor experiencia, mayor salario. Sin embargo, también hay recién ingresantes al trabajo que pudieron haber tenido uno similar previo y es por ello que a pesar de solo tener 1 año de experiencia reciben salarios muy altos."""

variables_finales.plot.scatter('P208A_y.1','ln_ingreso', marker ="+", s = 30, title="Edad", color="purple") #

plt.show()

"""Se puede observar que se forma una parábola concava. Esto se debe a que conforme aumenta la edad también aumentan los salarios pero solo hasta cierto momento. Luego se espera que los salarios comiencen a decaer así como en el gráfico."""

variables_finales.plot.scatter('P558D2_1','ln_ingreso', marker ="+", s = 30, title="Ubicación de lugar de trabajo (lejanía)", color="red") #

plt.show()

"""### PARTE III: A continuación, crearemos modelos para predecir el ingreso. Usaremos el 70% de la base para modelar y presentaremos los estadísticos resultados del modelo.

### 1. XGBoost
"""

# Seleccionamos los sets de variales
X = df[["OCUPINF", "P522A", "P558A1","P301A", "P513T", "P507", "ESTRATO_x","P513A1", "P208A_y.1","P558D2_1"]]
y = df['ln_ingreso']

X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=3/10,random_state=0)

# Definimos el modelo
model_1 = XGBRegressor()
# definir el método de evaluación del modelo
cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)
# Evaluar el modelo
scores = cross_val_score(model_1, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1)
# Forzamos que los resultados del score sean positivos
scores = absolute(scores)
print('Mean MAE: %.3f (%.3f)' % (scores.mean(), scores.std()) )

model_1.fit(X_train, y_train)

xgboost = model_1.predict(X_test)

print ('Mean Absolute Error:', metrics.mean_absolute_error(y_test, xgboost))
print ('Mean Squared Error:', metrics.mean_squared_error(y_test, xgboost))
print ('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, xgboost)))
print ("R2-score: %.2f" % r2_score(xgboost , y_test))

"""### 2.Regresión lineal

"""

# Seleccionamos los sets de variales
X = df[["OCUPINF", "P522A", "P558A1","P301A", "P513T", "P507", "ESTRATO_x","P513A1", "P208A_y.1","P558D2_1"]]
y = df['ln_ingreso']

X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=3/10,random_state=0)

# Usaremos la regresión lineal aquí ya que el salario es una variable continua. Con todos los datos, vemos que este es un caso de aprendizaje de Regresión Supervisada. Estableceremos el modelo de referencia aplicando la regresión lineal a feat_train, sal_train.
from sklearn.linear_model import LinearRegression
#Crear objeto de regresión lineal y ajustar el modelo
lm = LinearRegression()
lm.fit(X_train,y_train)
lm

#Ver el coeficiente del objeto de regresión lineal
print(lm.intercept_)
print(lm.coef_)

#predecir el salario usando datos de entrenamiento
yhat = lm.predict(X_train)

#Ver las primeras cinco predicciones -
print ('First five predictions:' , yhat[0:5])

# El error cuadrático medio (MSE) se evaluará ahora junto con la precisión y el cuadrado r para evaluar el rendimiento del modelo de referencia y determinar si los modelos posteriores mejoran con respecto al modelo de referencia establecido.

#Ver MSE - 
print ('Mean Squared Error of our prediction model', mean_squared_error(y_train, yhat))

print ('R-squared of test data-', lm.score(X_test, y_test))

"""### 3. Regresión lineal con características polinómicas: Ahora aplicaremos características polinómicas al modelo de regresión lineal ya construido y veremos si MSE se reduce y mejora la predcción."""

#forma y características -

print ('Number of training samples-', X_train.shape, '\n with the features-', X_train.columns)
print ('Number of testing samples-', X_test.shape, '\n with the features-', X_test.columns)
print ('Number of training salaries-', y_train.shape)
print ('Number of testing salaries-', y_test.shape )

#Ajusta y transforma las variables con polinomio de segundo orden
pr = PolynomialFeatures(2)
X_train_pr = pr.fit_transform(X_train)
X_test_pr = pr.fit_transform(X_test)
pr

#Crear un nuevo modelo usando Transformación Polinomial
poly = LinearRegression()
poly.fit(X_train_pr, y_train)

#hacer predicciones y ver las primeras cinco predicciones en los datos del tren - 
yhat_pr = poly.predict(X_train_pr)
print ('First five predictions(train data)-', yhat_pr[0:5])

#Compare los primeros cinco valores predichos con los valores reales -
print ('Predicted Values(train)-', yhat_pr[0:5])
print ('Actual Values(train)-', y_train[0:5].values)

#hacer predicciones y ver las primeras cinco predicciones en datos de prueba -
yhat_prtest = poly.predict(X_test_pr)
print ('First five predictions(test data)-', yhat_prtest[0:5])

#Compare los valores pronosticados de los datos de prueba y los valores reales de los datos de prueba -
print ('Predicted values(test)-', yhat_prtest[0:5])
print ('Actual values(test)-', y_test[0:5].values)

#imprimir valores R-cuadrados de datos de entrenamiento y prueba -
print ('R-squared of training data-', poly.score(X_train_pr, y_train))
print ('R-squared of testing data-', poly.score(X_test_pr, y_test))

"""### 4.Regresión RIDGE: Tenemos una definitiva mejora y por lo tanto ahora procederemos a tratar de mejor aun más el modelo. Para ello, comprobaremos si la aplicación de la regresión de Ridge reduce el MSE"""

from sklearn.linear_model import Ridge

# Modelo
RidgeModel = Ridge(alpha = 1.0)
RidgeModel.fit(X_train_pr, y_train)

#predict valores de datos de entrenamiento y datos de prueba
yhat_Ridge_train = RidgeModel.predict(X_train_pr)
yhat_Ridge_test = RidgeModel.predict(X_test_pr)

#compara los valores reales y predichos de los datos de entrenamiento
print ('Predicted Values(train)-', yhat_Ridge_train[0:5])
print ('Actual Values(train)-', X_train[0:5].values)

#compare los valores reales y predichos de los datos de prueba
print ('Predicted Values(test)-', yhat_Ridge_test[0:5])
print ('Actual Values(test)-', y_test[0:5].values)

#R-cuadrado de datos de entrenamiento y prueba -
print ('R-squared values(train)-', RidgeModel.score(X_train_pr, y_train))
print ('R-squared values(test)-', RidgeModel.score(X_test_pr, y_test))

#MSE de datos de entrenamiento y prueba -
print ('MSE of training data-', mean_squared_error(y_train, yhat_Ridge_train))
print ('MSE of testing data-', mean_squared_error(y_test, yhat_Ridge_test))

"""### 5.GRID SEARCH: En este caso, no observamos mejoras significativas. Ahora usemos Grid Search para asegurarnos de que se usen los hiperparámetros correctos:"""

#define el hiperparámetro 
parameters1 = [{'alpha': [0.001,0.1,1, 10, 100, 1000, 10000, 100000, 100000]}]
parameters1

#Crear un nuevo Ridge regression
RM = Ridge()

#create a gridsearch object and pass RM, parameters1 to it. 
from sklearn.model_selection import GridSearchCV

Grid = GridSearchCV(RM, parameters1, cv = 5)

#ajustar el modelo de búsqueda de cuadrícula a los datos de entrenamiento- 
Grid.fit(X_train, y_train)

#asignar mejor estimador -
bestRM = Grid.best_estimator_
bestRM

#Modelo de prueba usando datos de prueba -
bestRM.score(X_test, y_test)

"""### 6. RANDOM FOREST: Sin mejora usando alfa = 1. Por lo tanto, A continuación, intentemos usar Random Forest y Fit a Randomm Forest con random_state = 1 para mantener la coherencia."""

#Creamos un random forest object - 
from sklearn.ensemble import RandomForestRegressor

RF = RandomForestRegressor(n_estimators=100, random_state=10)
#fit a Random Forest model on training data - 
RF.fit(X_train, y_train)

#hacer predicciones sobre datos de prueba e imprimir los primeros cinco:
yhat_RF_test = RF.predict(X_test)
print ('First five predictions-', yhat_RF_test[0:5])

from sklearn import metrics

print ('MSE of test data-', mean_squared_error(y_test, yhat_RF_test))
print ('R-squared of test data-', RF.score(X_test, y_test))

"""#### La regresión lineal con transformación polinomial de segundo orden dio las mejores predicciones con un MSE de 0.364 y una precisión del 57 %. Esto cumple con el objetivo de reducir el MSE a menos de 360. Sin embargo, como segunda opción a seguir tendríamos el modelo XGBOOST. En la siguiente sección se hará el análisis correspondiente.

### PARTE IV: A continuación, usaremos el mejor modelo encontrado y aplicaremos los métodos de validación.

### En este caso para cada modelo hemos presentado un análisis del poder predictivo y el MSE. Además hemos podido observar la distribución de las predcciones.
"""

# XGBoost
Title = 'Distribution PLot of Actual Values vs Predicted Values'
dis_data(y_test, xgboost, 'Actual Values(train)', 'Predicted Values(train)', Title)

print ('Mean Absolute Error:', metrics.mean_absolute_error(y_test, xgboost))
print ('Mean Squared Error:', metrics.mean_squared_error(y_test, xgboost))
print ('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, xgboost)))
print ("R2-score: %.2f" % r2_score(xgboost , y_test))

# Regresión lineal

Title = 'Distribution PLot of Actual Values vs Predicted Values'
dis_data(y_test, yhat, 'Actual Values(train data)', 'Predicted Values(train data)', Title)
print ('R-squared of test data-', lm.score(X_test, y_test))
print ('Mean Squared Error of our prediction model', mean_squared_error(y_train, yhat))

# precisión del modelo de referencia utilizando el método de validación de 5 cruces -
score = cross_val_score(lm, X_train, y_train, cv = 5)
print ('5-Cross Validation accuracy', (np.mean(score)), (np.std(score)))

# Regresión lineal con características polinómicas
Title = 'Distribution PLot of Actual Values vs Predicted Values'
dis_data(y_test, yhat_pr, 'Actual Values(train)', 'Predicted Values(train)', Title)
print ('R-squared of training data-', poly.score(X_train_pr, y_train))
print ('R-squared of testing data-', poly.score(X_test_pr, y_test))

# Regresión Ridge
Title = 'Distribution PLot of Actual Values vs Predicted Values'
dis_data(y_test, yhat_Ridge_test, 'Actual Values(train)', 'Predicted Values(train)', Title)
#R-squared of training and testing data - 
print ('R-squared values(train)-', RidgeModel.score(X_train_pr, y_train))
print ('R-squared values(test)-', RidgeModel.score(X_test_pr, y_test))
#MSE of training and testing data - 
print ('MSE of training data-', mean_squared_error(y_train, yhat_Ridge_train))
print ('MSE of testing data-', mean_squared_error(y_test, yhat_Ridge_test))

# Random Forest
Title = 'Distribution PLot of Actual Values vs Predicted Values'
dis_data(y_test, yhat_RF_test, 'Actual Values(train)', 'Predicted Values(train)', Title)
print ('MSE of test data-', mean_squared_error(y_test, yhat_RF_test))
print ('R-squared of test data-', RF.score(X_test, y_test))

"""La regresión lineal con transformación polinomial de segundo orden dio las mejores predicciones con un MSE de 0.364 y una precisión del 57 %. Considero que el modelo podría mejorar si probamos otros predictores o si es que la data tuviera más disponibilidad de variables.

### PARTE V: Finalmente, crearmeos un gráfico de nube de puntos de los valores reales vs los predichos. Además, un histograma de los valores predichos superpuestos a los reales
"""

#Debido a que habíamos optado por dos posibles modelos, en este caso usaremos el XGOOST para el gráfico de dispersión

plt.figure(figsize=(10,10))
plt.scatter(y_test, yhat_Ridge_test, color='cyan')



p1 = max(max(xgboost), max(xgboost))
p2 = min(min(xgboost), min(xgboost))
plt.plot([p1, p2], [p1, p2], 'b-')
plt.xlabel('Valores reales', fontsize=15)
plt.ylabel('Predictions', fontsize=15)
plt.axis('equal')
plt.show()

"""- En este caso, se observa que existe una relación positiva entre los valores predichos y los valores que ya se tenían de la base de datos. Ello da buenos indicios sobre el uso del modelo y las variables para este trabajo. De esta manera, comprobamos que finalmente se ha predecido de la mejor manera posible con las variables disponibles
- EN este caso podemos predecir diferentes niveles de ingresos gracias a que tenemos una base de datos con muchas obervaciones. Se espera que aquellas personas con ingresos altas repitan patrones en características como educación, tipo de trabajo, lugar de vivienda, genero y entre otras. De esta manera, los algoritmos agrupan datos de las variables para hacer la mejro predicción posible.

"""

plt.figure(figsize=(10,5))
plt.hist([yhat_Ridge_test,y_test], bins=5, label=['predichos', 'reales'])
plt.legend(loc='upper left')
plt.show()

"""En este caso podríamos comentar que los valores predichos se encuentran ligeramente inflados en la parte media de la distribución. Sin embargo, para los ingresos muy altos la predicción está subestimada. Esto se puede deber a que no existne muchas observaciones con inbgresos muy altos. Lo mismo ocurre para la parte baja. Sin embargo, en la parte media tenemos la certeza de que la predcción está muy bien alineada."""